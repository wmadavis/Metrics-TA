---
title: "Problem Set 5 R Solutions and a Guide to Panel Data"
author: Matthew Alampay Davis
date: April 13, 2021
output:
  pdf_document: default
---

```{r, include = FALSE}
setwd('~/Documents/Grad School/Columbia/Y2/Intro Metrics TA/Past problem sets/PS5')
library(readstata13)
library(dplyr)
library(magrittr)
library(estimatr)
library(plm)
library(lmtest)
library(sandwich)
library(car)
library(car)
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff=60), tidy=TRUE)
```

We will use Question 2i as our guiding example for implementing panel data in R for the purpose of this course. The short of it is that we will implement it entirely using the familiar lm_robust function from *estimatr*. I know I directed some people to *plm* before the strike so apologies if it led to frustration during the problem set. This is why I write my own notes and didn't share the econometrics-with-R website before; it's pretty sloppy, often inaccurate, and I usually have to spend a day figuring out the differences between R and Stata.

Just for exposition, *plm* is a good package and can even handle robust standard errors. However by default it clusters standard errors to the level of the individual fixed effects. In general, we do want to use clustered standard errors whenever we include fixed effects which is why they've made it automatic, but this problem set does ask us to consider fixed-effects models without clustering so it cannot be used. Further, *lm_robust* is much more compatible with *linearHypothesis* when we run F-tests for a subset of covariates (such as fixed effects).

# Question 1

Let's load our data and create the log transformations we'll need:

```{r}
guns <- read.dta13('handguns.dta') %>%
  mutate(lvio = log(vio),
         lrob = log(rob),
         lmur = log(mur))
```

Regression (i): Regress ln(vio) against shall

```{r}
lm_robust(lvio ~ shall, data = guns, se_type = 'stata')
```

Regression (ii): Regress ln(vio) against shall, incarc_rate, density, avginc, pop, pb1064, pw1064, pm1029

```{r}
lm_robust(lvio ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029, data = guns, se_type = 'stata')
```

## 1a: Interpret the coefficient on shall in regression (ii). Is this estimate large or small in a “real-world” sense?

The coefficient of -0.37 means that holding constant the control variables (the incarceration rate in the previous year, the population density, state income, state population, percentage of blacks aged 10–64, percentage of whites aged 10-64, and percentage of male aged 10-29), having a "shall-carry"”" law results in a reduction in the violent crime rate of 37\%. This is a very large effect – a reduction in violent crimes of 37\% is very significant in a political or real-world sense.

## 1b: Does adding the control variables in regression (ii) change your conclusions about the effect of a shall-carry law, relative to regression (i)?

Adding the control variables reduces the estimated coefficient, suggesting that the original coefficient probably was subject to some omitted variable bias. In both (i) and (ii), the effect of the shall-carry law is statistically significant at the 5\% level. In (i) the estimated effect is a crime reduction of 44\%, in (ii) the estimated reduction is 37\%. Both estimated effects are very large. Still, in a real-world sense the difference between them is substantial also (7\% of violent crimes is a lot of crime).

## 1c: Suggest a variable which varies across states but plausibly varies little, or not at all, over time, and which plausibly could cause omitted variable bias in regression (ii)

Here is one:

Severity of punishment. Laws on violent crime are almost entirely state laws and there is considerable variation across states. Severity of punishment: (i) arguably affects the crime rate and (ii) could be correlated with shall-carry laws (Texas has the death penalty, it also has a shall-carry law). If so, the OLS estimate on shall arguably overstates the effect of having a shall-carry, which is, in part, picking up the effect of tough laws.

# Question 2


## 2i: Dependent variable ln(vio)

Running each regression in order

### Regression 1: no controls, no fixed effects, no clustering

```{r}
# 1
mod.2i.1 <- lm_robust(lvio ~ shall,
                      data = guns, se_type = 'stata')
summary(mod.2i.1)
```

This is the same as the first regression in Question 1. No fixed effects so we're treating this panel data like any data we do OLS on.

### Regression 2: **yes** controls, no fixed effects, no clustering

```{r}

mod.2i.2 <- lm_robust(lvio ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029,
                      data = guns, se_type = 'stata')
summary(mod.2i.2)
```

Again, this is the same as the second regression in Question 1. Don't forget to include the *se_type = 'stata'* argument!

### Regression 3: yes controls, **state** fixed effects, no clustering

Now we're exploiting the panel structure of the data by including fixed effects. *lm_robust* already includes a *fixed_effects* argument that handles these:

```{r}
mod.2i.3 <- lm_robust(lvio ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029,
                      fixed_effects = ~ state,
                      se_type = 'stata',
                      data = guns)
summary(mod.2i.3)
```

These give us exactly the same estimates and standard errors as Stata. I'll just flag here that when we read this regression output, make sure you get the decimal points correct. The coefficient on *shall* here is -4.614e-02, which means -0.04614 (move the decimal point to the left twice). I don't want you guys to lose points for something as silly as decimal places.

So the only downide here is that it omits the estimates on the fixed effects regressors, which makes it (as far as I know) impossible to do the F-test we want to do. So for that reason, we'll want to run this same model slightly differently by explicitly including the fixed effects in the right-hand side of the formula: "+ factor(state)". "factor" here just creates dummy variables for each state. If we did not use "factor" then it would treat *state* as one continuous variable taking on values from 1-50, which is not an implementation of fixed effects.

```{r}
mod.2i.3 <- lm_robust(lvio ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state),
                      se_type = 'stata',
                      data = guns)
summary(mod.2i.3)
```

The output is now much longer since we're including 50 fixed effects. But scroll up to the top and you'll find the estimates and standard errors on the main regressors are exactly the same.

Now let's do hypothesis testing on the fixed effects. We'll want to refer to the fixed effects by name so that we can use our familiar *linearHypothesis* function from the *car* package. But there are 50 of them, too many to type out manually. So let's first pull the vector of coefficients:

```{r}
mod.2i.3$coefficients
```

We only need their names rather than the actual estimates: 

```{r}
coef.names <- names(mod.2i.3$coefficients)
coef.names
```

Clearly, we only want the names that begin with "factor(state)" since those are the fixed effects. We can do this by observing that the fixed effects begin with variable 10 ("factor(state)Alaska") and go on to variable 59 ("factor(state)Wyoming") so that we can manually define state coefficients as follows:

```{r}
state.coefficients <- coef.names[10:59]
state.coefficients
```

Alternatively, let's use a new function (no new packages needed; it's standard in R) intuitively called *startsWith*. startsWith takes in a vector of strings/words as its first argument and a string of interest as its second argument. Then it outputs a vector that (obviously) outputs TRUE if it does begin with that string of interest and FALSE otherwise:

```{r}
startsWith(coef.names, 'factor(state)')
```

We use this as an index to select the coefficient names for which this is true:

```{r}
state.coefficients <- coef.names[startsWith(coef.names, 'factor(state)')]
state.coefficients
```

Exactly what we wanted. Now we just use this vector of variable names as the hypothesis argument in linearHypothesis. By default, this will jointly test the hypotheses that all these variables are equal to zero:

```{r}
linearHypothesis(mod.2i.3, state.coefficients, test = 'F')
```

Conveniently as usual, the output begins with the set of hypotheses we want to test so we know we're running the right test. The F-statistic is 210.38, exactly as Stata has it.

### Regression 4: yes controls, state **and year** fixed effects, no clustering

Again, we have the option to use the *fixed_effects* argument in *lm_robust* for the case with multiple fixed effects:

```{r}
mod.2i.4 <- lm_robust(lvio ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029,
                      fixed_effects = ~ state + year,
                      se_type = 'stata',
                      data = guns)
summary(mod.2i.4)
```

Note that once again, it's important to have the "~" to begin the "fixed_effects" argument (not sure why) and to separate the fixed effects dimensions with a "+" (with the individual fixed effects going first). Again, exactly the estiamtes and standard errors we wanted. Since we'll again be testing the fixed effects jointly for significance, we'll need to include the fixed effects as regressors explicitly:

```{r}
# 4
mod.2i.4 <- lm_robust(lvio ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state) + factor(year),
                      se_type = 'stata',
                      data = guns)
summary(mod.2i.4)
```

Now we want to test the state FEs separately from the 

```{r}
## F-statistic:
coef.names <- mod.2i.4$coefficients %>% names
state.coefficients <- coef.names[startsWith(coef.names, 'factor(state)')]
year.coefficients <- coef.names[startsWith(coef.names, 'factor(year)')]
linearHypothesis(mod.2i.4, state.coefficients, test = 'F')
linearHypothesis(mod.2i.4, year.coefficients, test = 'F')
```

### Regression 5: yes controls, state and year fixed effects, **yes** clustering

*lm_robust* includes a "clusters" argument. Always choose the individual dimension for clustering. And once again, do not forget the "se_type = 'stata'" argument:

```{r}
# 5
mod.2i.5 <- lm_robust(lvio ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state) + factor(year),
                      clusters = state,
                      se_type = 'stata',
                      data = guns)
summary(mod.2i.5)
```

This time, we only want to test the year fixed effects:

```{r}
year.coefficients <- coef.names[startsWith(coef.names, 'factor(year)')]
linearHypothesis(mod.2i.5, year.coefficients, test = 'F')
```

## 2ii: Dependent variable ln(rob)

I'll suppress the regression output so that we don't just produce a massive document full of fixed effects estimates, but the results do indeed match up exactly with the Stata solutions:

```{r}
# 1
mod.2ii.1 <- lm_robust(lrob ~ shall,
                      data = guns, se_type = 'stata')
# summary(mod.2ii.1)

# 2
mod.2ii.2 <- lm_robust(lrob ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029,
                      data = guns, se_type = 'stata')
# summary(mod.2ii.2)

# 3
mod.2ii.3 <- lm_robust(lrob ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state),
                      se_type = 'stata',
                      data = guns)
# summary(mod.2ii.3)
## F-statistic:
coef.names <- names(mod.2ii.3$coefficients)
state.coefficients <- coef.names[startsWith(coef.names, 'factor(state)')]
linearHypothesis(mod.2ii.3, state.coefficients, test = 'F')

# 4
mod.2ii.4 <- lm_robust(lrob ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state) + factor(year),
                      se_type = 'stata',
                      data = guns)
# summary(mod.2ii.4)
## F-statistic:
coef.names <- mod.2ii.4$coefficients %>% names
state.coefficients <- coef.names[startsWith(coef.names, 'factor(state)')]
year.coefficients <- coef.names[startsWith(coef.names, 'factor(year)')]
linearHypothesis(mod.2ii.4, state.coefficients, test = 'F')
linearHypothesis(mod.2ii.4, year.coefficients, test = 'F')

# 5
mod.2ii.5 <- lm_robust(lrob ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state) + factor(year),
                      clusters = state,
                      se_type = 'stata',
                      data = guns)
# summary(mod.2ii.5)
year.coefficients <- coef.names[startsWith(coef.names, 'factor(year)')]
linearHypothesis(mod.2ii.5, year.coefficients, test = 'F')
```

## 2iii: Dependent variable ln(mur)

```{r}
# 1
mod.2iii.1 <- lm_robust(lmur ~ shall,
                      data = guns, se_type = 'stata')
# summary(mod.2iii.1)

# 2
mod.2iii.2 <- lm_robust(lmur ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029,
                      data = guns, se_type = 'stata')
# summary(mod.2iii.2)

# 3
mod.2iii.3 <- lm_robust(lmur ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state),
                      se_type = 'stata',
                      data = guns)
# summary(mod.2iii.3)
## F-statistic:
coef.names <- names(mod.2iii.3$coefficients)
state.coefficients <- coef.names[startsWith(coef.names, 'factor(state)')]
linearHypothesis(mod.2iii.3, state.coefficients, test = 'F')

# 4
mod.2iii.4 <- lm_robust(lmur ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state) + factor(year),
                      se_type = 'stata',
                      data = guns)
# summary(mod.2iii.4)
## F-statistic:
coef.names <- mod.2iii.4$coefficients %>% names
state.coefficients <- coef.names[startsWith(coef.names, 'factor(state)')]
year.coefficients <- coef.names[startsWith(coef.names, 'factor(year)')]
linearHypothesis(mod.2iii.4, state.coefficients, test = 'F')
linearHypothesis(mod.2iii.4, year.coefficients, test = 'F')

# 5
mod.2iii.5 <- lm_robust(lmur ~ shall + incarc_rate + density + avginc + pop + pb1064 + pw1064 + pm1029 + factor(state) + factor(year),
                      clusters = state,
                      se_type = 'stata',
                      data = guns)
# summary(mod.2iii.5)
year.coefficients <- coef.names[startsWith(coef.names, 'factor(year)')]
linearHypothesis(mod.2iii.5, year.coefficients, test = 'F')
```

# Question 3

## 3a: What measures of firm performance would you include in an equation? What are some of the timing issues?

Potential measures of firm performance include: stock prices, percentage change in stock prices (i.e., returns), firm’s value (i.e., market capitalization), ROA, ROE, Net Income, and so on. Some of the timing issues can be that the previous day market performance and firm’s performance can influence the performance of the firm today. So, we may need to include lagged values of these performance measures.

## 3b: What other factors might you control for in the equation?

Firm’s performance could be influenced by other factors in addition to overall market performance. Some of these factors that you need to control for can include i) firm specific factors such as size of the firm, management quality, leverage, corporate social responsibility, etc. and ii) other macroeconomic factors like inflation, GDP, interest rates, and so on.

## 3c: Write an equation that allows you to estimate the effects of the overall stock market performance on the percentage change in firm’s stock price. How would you estimate this equation? Why would you choose this method?

An unobserved effects model is:

$$
\log\left(\frac{P_{i,t}}{P_{i,t-1}}\right) = \beta_0 + \alpha_i + \lambda_t + \beta_1 \log\left(\frac{SP_{i,t}}{SP_{i,t-1}}\right) + \beta_2\log(SIZE_{i,t})+...+u_{i,t}
$$
The outcome variable is the percentage change in stock prices or rate of return for firm $i$ at time $t$ and the ratio in the RHS is for the broad market. $\beta_1$ is the percentage change in firm performance given a one percentage-point increase in the market index. It is likely that $\alpha_i$ and $\lambda_t$ are correlated with firm size, and other control factors. So fixed effects (i.e., time and firm) estimation is appropriate.

## 3d: Implement your strategy discussed above using data from Yahoo Finance for any ten US companies of your choice as well as the stock price for the S\&P500

I don't think it's worth our time to go through this exercise since I'm doing multiple problem sets. Just a reminder here that the answer entails creating lagged and differenced variables, which we learned how to do in the context of time series (see: R guide to PS8 practice questions and R solutions to PS8 when I post them on Friday).