---
title: "PS6 R Solutions"
author: "Matthew Alampay Davis"
date: "December 2, 2021"
output:
  pdf_document: default
  html_notebook: default
---

```{r, include = FALSE}
setwd('~/Documents/Grad School/Columbia/Y3/Metrics TA/Pset R Solutions')
library(readstata13)
library(dplyr)
library(estimatr)
library(ggplot2)
library(magrittr)
library(car)
library(knitr)
library(lmtest)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```
# Question 1 #

```{r}
smoking <- read.dta13('smoking.dta') %>%
  mutate(age2 = age^2)
```

## Part a ##

Overall:

```{r}
# Overall
smoking$smoker %>% mean
```

Subsetting by whether there is a smoking ban

```{r}
smoking %>% group_by(smkban) %>% 
  summarize(smoker = mean(smoker))
```

## Part b ##

```{r}
mod.b <- lm_robust(smoker ~ smkban, smoking, se_type = 'stata')
summary(mod.b)
```
The probability of smoking is 7.8 percentage points (NOT percent) less if there is a smoking ban than if there is not. The t-statistic is -8.66 so the hypothesis that this difference is zero in population is rejected at the 1\% significance level.

## Part c ##

```{r}
mod.lpm <- lm_robust(smoker ~ smkban + female + age + age2 + hsdrop + hsgrad + colsome + colgrad + black + hispanic,
                   smoking, se_type = 'stata')
summary(mod.lpm)
```
After controlling for these additional variables, the estimated effect of a smoking ban is to reduce smoking by 4.7 percentage points, less than the 7.8 percentage points estimate without the control variables. This suggests that the original estimate was subject to omitted variable bias. For example, the estimated coefficients indicate that less educated individuals are more likely to smoke (condition (i) for omitted variable bias), but if less educated individuals also tend to work in places, like restaurants, that do not have smoking bans (condition (ii) for omitted variable bias), then having a smoking ban may be picking up the effect of education on smoking.

## Part d ##

The t-statistic is -5.27 so the hypothesis is rejected at the 5\% significance level.

## Part e ##

```{r}
linearHypothesis(mod.lpm, c('hsdrop = 0',
                            'hsgrad = 0',
                            'colsome = 0',
                            'colgrad = 0'),
                 test = 'F')
```
This requires an F-test because the null hypothesis is that the coefficients on hsdrop, hsgrad, colsome, and colgrad are all zero in population. The p-value is <.001 so the hypothesis is rejected at the 1\% significance level. The less education, the larger are the coefficients, so they indicate that the probability of smoking is observed to decrease with education, holding the other regressors constant. For example, the probability of smoking is predicted to be 32.3 percentage points greater for a high school dropout than for the omitted group (those with a Masterâ€™s degree or higher).

## Part f ##

Probit:

```{r}
mod.probit <- glm(smoker ~ smkban + female + age + age2 + hsdrop + hsgrad + colsome + colgrad + black + hispanic,
                  smoking, family = binomial(link = 'probit'))
coeftest(mod.probit, type = 'HC1')
```
Logit:

```{r}
mod.logit <- glm(smoker ~ smkban + female + age + age2 + hsdrop + hsgrad + colsome + colgrad + black + hispanic,
                  smoking, family = binomial(link = 'logit'))
coeftest(mod.logit, type = 'HC1')
```
Predicted probabilities:

```{r}
# Cases: Mr. A + ban, Mr. A + no ban, Ms. B + ban, Ms. B + no ban
cases <- data.frame(smkban = c(1,0,1,0),
                    female = c(0,0,1,1),
                    age = c(20,20,40,40),
                    age2 = c(20^2,20^2,40^2,40^2),
                    hsdrop = c(1,1,0,0),
                    hsgrad = c(0,0,0,0),
                    colsome = c(0,0,0,0),
                    colgrad = c(0,0,1,1),
                    black = c(0,0,1,1),
                    hispanic = c(0,0,0,0))
predict(mod.probit, newdata = cases, type = 'response')
predict(mod.logit, newdata = cases, type = 'response')
predict(mod.lpm, newdata = cases)
```

### Part f (1): Probit
```{r}
# PROBIT -- MR. A

## (1)(i)
predict(mod.probit, newdata = cases, type = 'response')[1]
## (1)(ii)
predict(mod.probit, newdata = cases, type = 'response')[2]
## Diff
predict(mod.probit, newdata = cases, type = 'response')[1]-predict(mod.probit, newdata = cases, type = 'response')[2]

# PROBIT -- MS. B
## (1)(iii)
predict(mod.probit, newdata = cases, type = 'response')[3]
## (1)(iv)
predict(mod.probit, newdata = cases, type = 'response')[4]
## Diff
predict(mod.probit, newdata = cases, type = 'response')[3]-predict(mod.probit, newdata = cases, type = 'response')[4]
```

### Part f (2): Logit

```{r}
# LOGIT -- MR. A

## (2)(i)
predict(mod.logit, newdata = cases, type = 'response')[1]
## (2)(ii)
predict(mod.logit, newdata = cases, type = 'response')[2]
## Diff
predict(mod.logit, newdata = cases, type = 'response')[1]-predict(mod.logit, newdata = cases, type = 'response')[2]

# logit -- MS. B
## (2)(iii)
predict(mod.logit, newdata = cases, type = 'response')[3]
## (2)(iv)
predict(mod.logit, newdata = cases, type = 'response')[4]
## Diff
predict(mod.logit, newdata = cases, type = 'response')[3]-predict(mod.logit, newdata = cases, type = 'response')[4]
```

### Part f (3): Linear Probability Model

```{r}
# LPM -- MR. A

## (3)(i)
predict(mod.lpm, newdata = cases)[1]
## (3)(ii)
predict(mod.lpm, newdata = cases)[2]
## Diff
predict(mod.lpm, newdata = cases)[1]-predict(mod.lpm, newdata = cases)[2]

# LPM -- MS. B
## (3)(iii)
predict(mod.lpm, newdata = cases)[3]
## (3)(iv)
predict(mod.lpm, newdata = cases)[4]
## Diff
predict(mod.lpm, newdata = cases)[3]-predict(mod.lpm, newdata = cases)[4]
```

We can also calculate the percentage correctly predicted for each model:

```{r}
# Probit
table(smoking$smoker==round(mod.probit$fitted.values)) %>% prop.table

# Logit
table(smoking$smoker==round(mod.logit$fitted.values)) %>% prop.table

# LPM
table(smoking$smoker==round(mod.lpm$fitted.values)) %>% prop.table
```

Questions 2 and 3 are non-empirical so just use the same answer as in the official solutions. Only thing I would flag is that for 2a, I believe the probability of living on her own increases with age up to age 30, not 60 as the answers indicate.